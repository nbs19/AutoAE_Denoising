{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "**Importing Drive**"
      ],
      "metadata": {
        "id": "a2lG3pzofVo_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PK0fg-9aE1QG",
        "outputId": "7ea420a4-2ca1-4ec7-9be0-f601bc279a68"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Defining Paths**"
      ],
      "metadata": {
        "id": "4qLX4ej2fanm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import cv2\n",
        "import numpy as np\n",
        "from skimage.metrics import structural_similarity as ssim\n",
        "from skimage.metrics import peak_signal_noise_ratio as psnr\n",
        "from google.colab.patches import cv2_imshow\n",
        "import torchvision.transforms as transforms\n",
        "from PIL import Image\n",
        "\n",
        "def get_paths_of_an_object(root, object_name, folder=\"Val\", type=\"Degraded_image\" ):\n",
        "\n",
        " root=root+\"/drive/MyDrive\"\n",
        "\n",
        " dataset_path=os.path.join(root, \"Denoising_Dataset_train_val\")\n",
        "\n",
        " image_paths=[]\n",
        "\n",
        "\n",
        "\n",
        " for object in sorted(os.listdir(dataset_path)):\n",
        "\n",
        "  if object==object_name:\n",
        "\n",
        "    object_directory_path=os.path.join(root, \"Denoising_Dataset_train_val\", object)\n",
        "\n",
        "\n",
        "    for train_folder in sorted(os.listdir(object_directory_path)):\n",
        "\n",
        "      if(train_folder==folder): #validation folder\n",
        "\n",
        "        train_directory_path=os.path.join(root, \"Denoising_Dataset_train_val\", object, train_folder)\n",
        "\n",
        "\n",
        "        for degraded_image_folder in os.listdir(train_directory_path):\n",
        "\n",
        "            if(degraded_image_folder==type):\n",
        "\n",
        "\n",
        "\n",
        "                image_folder_path=os.listdir(os.path.join(root, \"Denoising_Dataset_train_val\", object, train_folder, degraded_image_folder))\n",
        "\n",
        "                for image_folder in sorted(image_folder_path):\n",
        "\n",
        "                    image_path=os.listdir(os.path.join(root, \"Denoising_Dataset_train_val\", object, train_folder, degraded_image_folder, image_folder))\n",
        "\n",
        "                    for image in sorted(image_path):\n",
        "\n",
        "                        image_paths.append(os.path.join(root, \"Denoising_Dataset_train_val\", object, train_folder, degraded_image_folder, image_folder, image))\n",
        "\n",
        " return image_paths"
      ],
      "metadata": {
        "id": "h1DVVd1pNK4N"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import shutil\n",
        "\n",
        "# Specify the path to the denoised_images folder\n",
        "denoised_images_path = '/content/denoised_images/'\n",
        "\n",
        "# Check if the directory exists\n",
        "if os.path.exists(denoised_images_path):\n",
        "    # Remove all contents of the directory\n",
        "    shutil.rmtree(denoised_images_path)\n",
        "    # Recreate the empty denoised_images folder\n",
        "    os.makedirs(denoised_images_path)\n",
        "    print(\"All contents of the denoised_images folder have been deleted.\")\n",
        "else:\n",
        "    print(\"The specified directory does not exist.\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FtseKMWTrTpf",
        "outputId": "f069cdf1-673a-4595-a866-47a60e8503e2"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "All contents of the denoised_images folder have been deleted.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Model Architecture**"
      ],
      "metadata": {
        "id": "MJ0hPDfffgMG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import cv2\n",
        "import numpy as np\n",
        "from torchvision import transforms\n",
        "\n",
        "# Step 1: Define your model architecture\n",
        "import torch.nn.init as init\n",
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "\n",
        "import torch.nn.init as init\n",
        "\n",
        "class DnCNN(nn.Module):\n",
        "\n",
        "    def __init__(self, depth=15, n_channels=64, image_channels=1, use_bnorm=True, kernel_size=3):\n",
        "\n",
        "        super(DnCNN, self).__init__()\n",
        "\n",
        "        kernel_size = 3\n",
        "\n",
        "        padding = 1\n",
        "\n",
        "        layers = []\n",
        "\n",
        "\n",
        "\n",
        "        layers.append(nn.Conv2d(in_channels=image_channels, out_channels=n_channels, kernel_size=kernel_size, padding=padding, bias=True))\n",
        "\n",
        "        layers.append(nn.ReLU(inplace=True))\n",
        "\n",
        "        for _ in range(depth-2):\n",
        "\n",
        "            layers.append(nn.Conv2d(in_channels=n_channels, out_channels=n_channels, kernel_size=kernel_size, padding=padding, bias=False))\n",
        "\n",
        "            layers.append(nn.BatchNorm2d(n_channels, eps=0.0001, momentum = 0.95))\n",
        "\n",
        "            layers.append(nn.ReLU(inplace=True))\n",
        "\n",
        "        layers.append(nn.Conv2d(in_channels=n_channels, out_channels=image_channels, kernel_size=kernel_size, padding=padding, bias=False))\n",
        "\n",
        "        self.dncnn = nn.Sequential(*layers)\n",
        "\n",
        "        self._initialize_weights()\n",
        "\n",
        "\n",
        "\n",
        "    def forward(self, x):\n",
        "\n",
        "        y = x\n",
        "\n",
        "        out = self.dncnn(x)\n",
        "\n",
        "        denoised_output = y - out\n",
        "\n",
        "        return torch.clamp(denoised_output, 0, 1)\n",
        "\n",
        "\n",
        "\n",
        "    def _initialize_weights(self):\n",
        "\n",
        "        for m in self.modules():\n",
        "\n",
        "            if isinstance(m, nn.Conv2d):\n",
        "\n",
        "                init.orthogonal_(m.weight)\n",
        "\n",
        "                if m.bias is not None:\n",
        "\n",
        "                    init.constant_(m.bias, 0)\n",
        "\n",
        "            elif isinstance(m, nn.BatchNorm2d):\n",
        "\n",
        "                init.constant_(m.weight, 1)\n",
        "\n",
        "                init.constant_(m.bias, 0)\n",
        "\n",
        "# Step 2: Create a model instance\n",
        "model = DnCNN(depth=14, n_channels=64, image_channels=3).to(device)"
      ],
      "metadata": {
        "id": "d2iPIdg6Nk_k"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Loading best model**"
      ],
      "metadata": {
        "id": "jU_jEHA0flUe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "# Step 3: Load the state_dict with weights_only=True\n",
        "model.load_state_dict(torch.load('/content/Best_model.pth'))\n",
        "model.eval()  # Set the model to evaluation mode\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "T-nsiaVNFHjV",
        "outputId": "9b450064-f903-4af3-beef-a6ab7f639741"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-7-bb8a184c04a8>:2: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  model.load_state_dict(torch.load('/content/Best_model.pth'))\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "DnCNN(\n",
              "  (dncnn): Sequential(\n",
              "    (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (1): ReLU(inplace=True)\n",
              "    (2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "    (3): BatchNorm2d(64, eps=0.0001, momentum=0.95, affine=True, track_running_stats=True)\n",
              "    (4): ReLU(inplace=True)\n",
              "    (5): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "    (6): BatchNorm2d(64, eps=0.0001, momentum=0.95, affine=True, track_running_stats=True)\n",
              "    (7): ReLU(inplace=True)\n",
              "    (8): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "    (9): BatchNorm2d(64, eps=0.0001, momentum=0.95, affine=True, track_running_stats=True)\n",
              "    (10): ReLU(inplace=True)\n",
              "    (11): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "    (12): BatchNorm2d(64, eps=0.0001, momentum=0.95, affine=True, track_running_stats=True)\n",
              "    (13): ReLU(inplace=True)\n",
              "    (14): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "    (15): BatchNorm2d(64, eps=0.0001, momentum=0.95, affine=True, track_running_stats=True)\n",
              "    (16): ReLU(inplace=True)\n",
              "    (17): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "    (18): BatchNorm2d(64, eps=0.0001, momentum=0.95, affine=True, track_running_stats=True)\n",
              "    (19): ReLU(inplace=True)\n",
              "    (20): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "    (21): BatchNorm2d(64, eps=0.0001, momentum=0.95, affine=True, track_running_stats=True)\n",
              "    (22): ReLU(inplace=True)\n",
              "    (23): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "    (24): BatchNorm2d(64, eps=0.0001, momentum=0.95, affine=True, track_running_stats=True)\n",
              "    (25): ReLU(inplace=True)\n",
              "    (26): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "    (27): BatchNorm2d(64, eps=0.0001, momentum=0.95, affine=True, track_running_stats=True)\n",
              "    (28): ReLU(inplace=True)\n",
              "    (29): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "    (30): BatchNorm2d(64, eps=0.0001, momentum=0.95, affine=True, track_running_stats=True)\n",
              "    (31): ReLU(inplace=True)\n",
              "    (32): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "    (33): BatchNorm2d(64, eps=0.0001, momentum=0.95, affine=True, track_running_stats=True)\n",
              "    (34): ReLU(inplace=True)\n",
              "    (35): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "    (36): BatchNorm2d(64, eps=0.0001, momentum=0.95, affine=True, track_running_stats=True)\n",
              "    (37): ReLU(inplace=True)\n",
              "    (38): Conv2d(64, 3, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "  )\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Objects Names**"
      ],
      "metadata": {
        "id": "VAPWRmaJfqaG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def get_object_names(root): #returns paths of all the images of a given object\n",
        "\n",
        " root=root+\"/drive/MyDrive\"\n",
        "\n",
        " dataset_path=os.path.join(root, \"Denoising_Dataset_train_val\")\n",
        "\n",
        " object_names=[]\n",
        "\n",
        "\n",
        "\n",
        " for object in sorted(os.listdir(dataset_path)):\n",
        "\n",
        "  object_names.append(object)\n",
        "\n",
        "\n",
        "\n",
        " return object_names\n",
        "\n",
        "\n",
        "\n",
        "objects=get_object_names(os.getcwd())\n",
        "\n",
        "objects"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aj0NX31ZRWDZ",
        "outputId": "e3b5b294-60d9-42cc-f66b-61c0d8d415d5"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['bottle',\n",
              " 'cable',\n",
              " 'capsule',\n",
              " 'carpet',\n",
              " 'grid',\n",
              " 'hazelnut',\n",
              " 'leather',\n",
              " 'metal_nut',\n",
              " 'pill',\n",
              " 'screw',\n",
              " 'tile',\n",
              " 'toothbrush',\n",
              " 'transistor',\n",
              " 'wood',\n",
              " 'zipper']"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "\n",
        "# Check if the main dataset directory exists\n",
        "root = '/content/drive/MyDrive'  # or adjust to your actual root if needed\n",
        "dataset_path = os.path.join(root, \"Denoising_Dataset_train_val\")\n",
        "print(\"Checking dataset path:\", dataset_path)\n",
        "\n",
        "if not os.path.exists(dataset_path):\n",
        "    print(f\"Dataset path does not exist: {dataset_path}\")\n",
        "else:\n",
        "    print(\"Dataset path exists. Contents:\", os.listdir(dataset_path))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RGx6Nr_cSa3B",
        "outputId": "3f94c7bb-3d20-4588-d7e9-454b7f64c603"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Checking dataset path: /content/drive/MyDrive/Denoising_Dataset_train_val\n",
            "Dataset path exists. Contents: ['screw', 'transistor', 'hazelnut', 'toothbrush', 'tile', 'pill', 'zipper', 'metal_nut', 'wood', 'leather', 'grid', 'cable', 'bottle', 'capsule', 'carpet']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Finding PSNR ANd saving denoised iamges in corresponding folders**"
      ],
      "metadata": {
        "id": "kHZ_u_O06FaN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import torch\n",
        "from torchvision import transforms\n",
        "from PIL import Image\n",
        "from skimage.metrics import peak_signal_noise_ratio as psnr\n",
        "\n",
        "# Define your image transformations here\n",
        "transform = transforms.Compose([\n",
        "    transforms.Resize((256, 256)),  # Resize images to 256x256\n",
        "    transforms.ToTensor(),            # Convert images to tensor\n",
        "])\n",
        "\n",
        "# Specify the main output directory for denoised images\n",
        "output_directory = '/content/denoised_images'\n",
        "os.makedirs(output_directory, exist_ok=True)  # Create the main directory if it doesn't exist\n",
        "\n",
        "model.eval()\n",
        "\n",
        "with torch.inference_mode():\n",
        "    psnr_scores = []  # Initialize list to store PSNR scores\n",
        "\n",
        "    for object in objects:\n",
        "        degraded_object_image_paths = get_paths_of_an_object('/content', object)\n",
        "        clean_object_image_paths = get_paths_of_an_object('/content', object, \"Val\", \"GT_clean_image\")\n",
        "\n",
        "        # Load and transform degraded images\n",
        "        degraded_images = torch.zeros(len(degraded_object_image_paths), 3, 256, 256)\n",
        "        for i, noisy_image in enumerate(degraded_object_image_paths):\n",
        "            pil_image = Image.open(noisy_image)\n",
        "            noisy = transform(pil_image)  # Use the defined transform\n",
        "            degraded_images[i] = noisy\n",
        "\n",
        "        # Load and transform clean images\n",
        "        clean_images = torch.zeros(len(clean_object_image_paths), 3, 256, 256)\n",
        "        for i, image in enumerate(clean_object_image_paths):\n",
        "            pil_image = Image.open(image)\n",
        "            image = transform(pil_image)  # Use the defined transform\n",
        "            clean_images[i] = image\n",
        "\n",
        "        # Pass degraded images through the model\n",
        "        reconstructed_images = model(degraded_images.to(device))\n",
        "\n",
        "        # Convert tensors to numpy arrays for PSNR calculation\n",
        "        reconstructed_images_np = reconstructed_images.cpu().detach().numpy()\n",
        "        clean_images_np = clean_images.cpu().detach().numpy()\n",
        "\n",
        "        # Calculate PSNR\n",
        "        psnr_score = psnr(reconstructed_images_np, clean_images_np)  # Calculate PSNR\n",
        "        psnr_scores.append(psnr_score)\n",
        "\n",
        "        print(f\"PSNR for {object} is {psnr_score:.2f}\")\n",
        "\n",
        "        # Create a subdirectory for the current object category\n",
        "        category_directory = os.path.join(output_directory, object)\n",
        "        os.makedirs(category_directory, exist_ok=True)  # Create the category directory if it doesn't exist\n",
        "\n",
        "        # Save the denoised images in the category directory\n",
        "        for i in range(reconstructed_images_np.shape[0]):\n",
        "            # Convert the denoised tensor to a PIL image\n",
        "            denoised_image = transforms.ToPILImage()(reconstructed_images[i].cpu())\n",
        "            # Define the path to save the image\n",
        "            denoised_image_path = os.path.join(category_directory, f\"{object}_denoised_{i}.png\")\n",
        "            # Save the image\n",
        "            denoised_image.save(denoised_image_path)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bKJagiHpn6CO",
        "outputId": "2634d7e2-62d3-4437-9e70-0b871c2cb93d"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "PSNR for bottle is 26.01\n",
            "PSNR for cable is 23.96\n",
            "PSNR for capsule is 24.55\n",
            "PSNR for carpet is 21.17\n",
            "PSNR for grid is 23.29\n",
            "PSNR for hazelnut is 28.96\n",
            "PSNR for leather is 27.58\n",
            "PSNR for metal_nut is 26.81\n",
            "PSNR for pill is 28.24\n",
            "PSNR for screw is 24.99\n",
            "PSNR for tile is 23.59\n",
            "PSNR for toothbrush is 27.24\n",
            "PSNR for transistor is 26.38\n",
            "PSNR for wood is 26.32\n",
            "PSNR for zipper is 26.89\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}